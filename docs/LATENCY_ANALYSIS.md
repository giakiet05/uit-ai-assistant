"""
COMPLETE FLOW ANALYSIS: User Question ‚Üí Agent Response
=========================================================

Example Query: "ƒêi·ªÉm TOEIC t·ªët nghi·ªáp l√† bao nhi√™u?"

FLOW BREAKDOWN (v·ªõi timing ∆∞·ªõc t√≠nh):
======================================

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. USER ‚Üí API GATEWAY (Frontend ‚Üí Backend)                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ - Frontend g·ª≠i HTTP POST /api/v1/chat                          ‚îÇ
‚îÇ - API Gateway nh·∫≠n request, validate JWT, extract user_id      ‚îÇ
‚îÇ - Timing: ~50-100ms                                            ‚îÇ
‚îÇ - Bottleneck: NO                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. API GATEWAY ‚Üí AGENT (gRPC Call)                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ - API Gateway g·ªçi AgentService.Chat() qua gRPC                 ‚îÇ
‚îÇ - Create/load session t·ª´ MongoDB                               ‚îÇ
‚îÇ - Load chat history (n·∫øu c√≥)                                   ‚îÇ
‚îÇ - Timing: ~100-200ms (local), ~200-500ms (v·ªõi DB query)        ‚îÇ
‚îÇ - Bottleneck: SLIGHT (n·∫øu history d√†i)                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. AGENT - LangGraph Orchestration                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Step 3.1: Query Refinement (OPTIONAL - n·∫øu b·∫≠t)                ‚îÇ
‚îÇ   - G·ªçi LLM ƒë·ªÉ refine query                                    ‚îÇ
‚îÇ   - Model: gpt-5-nano                                          ‚îÇ
‚îÇ   - Timing: ~500ms-1s ‚ö†Ô∏è                                       ‚îÇ
‚îÇ   - Bottleneck: YES n·∫øu b·∫≠t                                    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ Step 3.2: LLM Planning (OpenAI API)                            ‚îÇ
‚îÇ   - Agent LLM quy·∫øt ƒë·ªãnh g·ªçi tool n√†o                         ‚îÇ
‚îÇ   - Model: gpt-5 (l·ªõn, ch·∫≠m)                                  ‚îÇ
‚îÇ   - Input: System prompt + history + user query               ‚îÇ
‚îÇ   - Timing: ~2-4s ‚ö†Ô∏è‚ö†Ô∏è (SLOW!)                                ‚îÇ
‚îÇ   - Bottleneck: YES - OpenAI API latency                      ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ Step 3.3: Tool Call Decision                                   ‚îÇ
‚îÇ   - Parse tool name v√† arguments t·ª´ LLM response              ‚îÇ
‚îÇ   - Timing: ~10ms                                             ‚îÇ
‚îÇ   - Bottleneck: NO                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. AGENT ‚Üí MCP SERVER (Tool Execution)                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ - Agent g·ªçi retrieve_regulation() qua MCP protocol             ‚îÇ
‚îÇ - Transport: HTTP SSE (streamable-http)                        ‚îÇ
‚îÇ - Timing overhead: ~50-100ms                                   ‚îÇ
‚îÇ - Bottleneck: SLIGHT                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. MCP SERVER - Retrieval Pipeline                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Step 5.1: HyDE (OPTIONAL - hi·ªán t·∫°i T·∫ÆT)                       ‚îÇ
‚îÇ   - Generate hypothetical document v·ªõi LLM                     ‚îÇ
‚îÇ   - Timing: ~500ms-1s (n·∫øu b·∫≠t)                               ‚îÇ
‚îÇ   - Bottleneck: YES n·∫øu b·∫≠t                                    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ Step 5.2: Vector Search (ChromaDB)                             ‚îÇ
‚îÇ   - Embed query v·ªõi OpenAI text-embedding-3-small             ‚îÇ
‚îÇ   - Embedding API call: ~200-300ms ‚ö†Ô∏è                         ‚îÇ
‚îÇ   - Vector search trong ChromaDB: ~50-100ms                   ‚îÇ
‚îÇ   - Retrieve top-20 chunks                                     ‚îÇ
‚îÇ   - Total: ~300-400ms                                         ‚îÇ
‚îÇ   - Bottleneck: MODERATE (embedding API)                      ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ Step 5.3: Reranking (Cohere API ho·∫∑c Modal)                    ‚îÇ
‚îÇ   - G·ª≠i 20 chunks + query t·ªõi reranker                        ‚îÇ
‚îÇ   - Modal GPU reranker: ~500-800ms ‚ö†Ô∏è                         ‚îÇ
‚îÇ   - Local CPU reranker: ~2-3s ‚ö†Ô∏è‚ö†Ô∏è                            ‚îÇ
‚îÇ   - Filter top-k (default: 3-5 chunks)                        ‚îÇ
‚îÇ   - Bottleneck: YES - especially if local CPU                 ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ Step 5.4: Context Distillation (N·∫æU B·∫¨T)                       ‚îÇ
‚îÇ   - Extract table HTML (~10ms)                                ‚îÇ
‚îÇ   - G·ªçi gpt-5-nano cho distillation                           ‚îÇ
‚îÇ   - LLM processing: ~1-2s per chunk ‚ö†Ô∏è                        ‚îÇ
‚îÇ   - V·ªõi 5 chunks: ~5-10s ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è (VERY SLOW!)                 ‚îÇ
‚îÇ   - Bottleneck: YES - MAJOR SLOWDOWN                          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ Step 5.5: Format Results                                       ‚îÇ
‚îÇ   - Convert nodes ‚Üí structured JSON                            ‚îÇ
‚îÇ   - Timing: ~10-20ms                                          ‚îÇ
‚îÇ   - Bottleneck: NO                                            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ TOTAL MCP RETRIEVAL:                                           ‚îÇ
‚îÇ   - Without distillation: ~1-2s                               ‚îÇ
‚îÇ   - With distillation: ~6-12s ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. AGENT - Tool Response Processing                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Step 6.1: Receive tool result t·ª´ MCP                          ‚îÇ
‚îÇ   - Parse JSON response                                        ‚îÇ
‚îÇ   - Timing: ~10ms                                             ‚îÇ
‚îÇ   - Bottleneck: NO                                            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ Step 6.2: LLM Final Answer (OpenAI API)                        ‚îÇ
‚îÇ   - Agent LLM ƒë·ªçc tool result v√† sinh c√¢u tr·∫£ l·ªùi            ‚îÇ
‚îÇ   - Model: gpt-5 (l·ªõn)                                        ‚îÇ
‚îÇ   - Input: System + history + tool result + query             ‚îÇ
‚îÇ   - V·ªõi distilled_context: input ng·∫Øn h∆°n                     ‚îÇ
‚îÇ   - Timing: ~2-5s ‚ö†Ô∏è‚ö†Ô∏è                                        ‚îÇ
‚îÇ   - Bottleneck: YES - OpenAI API latency                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 7. AGENT ‚Üí API GATEWAY ‚Üí USER (Response Path)                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ - Agent tr·∫£ response v·ªÅ API Gateway qua gRPC                   ‚îÇ
‚îÇ - API Gateway save message to MongoDB                          ‚îÇ
‚îÇ - API Gateway tr·∫£ HTTP response cho frontend                   ‚îÇ
‚îÇ - Timing: ~100-200ms                                          ‚îÇ
‚îÇ - Bottleneck: NO                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò


SUMMARY - TOTAL LATENCY:
=========================

WITHOUT Context Distillation:
------------------------------
1. API Gateway receive          : ~100ms
2. Agent load session           : ~200ms
3. Agent LLM planning          : ~3s      ‚ö†Ô∏è SLOW
4. MCP transport               : ~100ms
5. MCP embedding API           : ~300ms
6. MCP reranking (Modal)       : ~700ms   ‚ö†Ô∏è MODERATE
7. MCP format                  : ~20ms
8. Agent LLM final answer      : ~3s      ‚ö†Ô∏è SLOW
9. Response path               : ~200ms

TOTAL: ~7-8 seconds
------------------------------


WITH Context Distillation (CURRENT):
-------------------------------------
1-3. Same as above             : ~3.4s
4.  MCP transport              : ~100ms
5.  MCP embedding API          : ~300ms
6.  MCP reranking (Modal)      : ~700ms
7.  Context Distillation       : ~8s     ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è VERY SLOW!
8.  MCP format                 : ~20ms
9.  Agent LLM final answer     : ~2s     (nhanh h∆°n v√¨ input ng·∫Øn)
10. Response path              : ~200ms

TOTAL: ~14-15 seconds ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
-------------------------------------


TOP BOTTLENECKS (ranked by impact):
====================================

üî¥ 1. CONTEXT DISTILLATION (~8s)
   - Root cause: 
     * G·ªçi LLM 5 l·∫ßn (1 l·∫ßn/chunk) tu·∫ßn t·ª±
     * Model gpt-5-nano v·∫´n c√≥ latency ~1-2s/call
     * Total: 5 chunks √ó 1.5s = 7.5s
   
   - Solutions:
     ‚úÖ ƒêANG D√ôNG: Parallel processing (ƒë√£ implement)
        ‚Üí Gi·∫£m t·ª´ ~7.5s xu·ªëng ~2s (fastest chunk wins)
     
     ‚ùå CH∆ØA APPLY: Th·ª±c t·∫ø c√≥ th·ªÉ v·∫´n ch·∫≠m v√¨:
        ‚Üí Code m·ªõi ch∆∞a restart?
        ‚Üí Ho·∫∑c ƒëang distill to√†n b·ªô context (kh√¥ng ph·∫£i t·ª´ng chunk)?
     
     üîß RECOMMEND:
        - T·∫Øt distillation t·∫°m (USE_CONTEXT_DISTILLATION=false)
        - Ho·∫∑c tƒÉng DISTILLATION_MIN_CHUNKS l√™n 10
          (ch·ªâ distill khi retrieve >10 chunks, hi·∫øm x·∫£y ra)

üî¥ 2. AGENT LLM PLANNING (~3s)
   - Root cause: OpenAI API latency v·ªõi gpt-5
   
   - Solutions:
     üîß D√πng gpt-5-mini cho planning (nh·∫π h∆°n)
     üîß Cache system prompt
     üîß Streaming response (user th·∫•y thinking s·ªõm h∆°n)

üî¥ 3. AGENT LLM FINAL ANSWER (~3s without distillation, ~2s with)
   - Root cause: OpenAI API latency
   
   - Solutions:
     üîß Streaming response
     üîß V·ªõi distillation: ƒë√£ nhanh h∆°n nh·ªù input ng·∫Øn

üü° 4. RERANKING (~700ms Modal, ~2-3s local CPU)
   - Root cause: External API call ho·∫∑c CPU inference
   
   - Solutions:
     ‚úÖ ƒê√£ d√πng Modal GPU (t·ªët r·ªìi)
     üîß Gi·∫£m top_k t·ª´ 20 ‚Üí 10 (√≠t chunks h∆°n ƒë·ªÉ rerank)

üü° 5. EMBEDDING API (~300ms)
   - Root cause: OpenAI API latency
   
   - Solutions:
     üîß Kh√¥ng th·ªÉ t·ªëi ∆∞u nhi·ªÅu (c·∫ßn API call)
     üîß C√≥ th·ªÉ cache embeddings cho queries ph·ªï bi·∫øn


RECOMMENDATIONS - GI·∫¢M LATENCY NGAY:
=====================================

PRIORITY 1 - T·∫ÆT/GI·ªöI H·∫†N CONTEXT DISTILLATION:
------------------------------------------------
```bash
# Option A: T·∫Øt ho√†n to√†n (nhanh nh·∫•t)
USE_CONTEXT_DISTILLATION=false

# Option B: Ch·ªâ distill khi qu√° nhi·ªÅu chunks
USE_CONTEXT_DISTILLATION=true
DISTILLATION_MIN_CHUNKS=10  # Hi·∫øm khi trigger

# Restart MCP server
```
Expected gain: **-7s** (14s ‚Üí 7s) ‚ö†Ô∏è HUGE IMPACT!


PRIORITY 2 - STREAMING RESPONSE:
---------------------------------
- Agent stream t·ª´ng chunk c√¢u tr·∫£ l·ªùi v·ªÅ frontend
- User th·∫•y text appear t·ª´ t·ª´ thay v√¨ ƒë·ª£i h·∫øt
- Kh√¥ng gi·∫£m total time, nh∆∞ng PERCEIVED latency gi·∫£m m·∫°nh
- Frontend c·∫ßn update ƒë·ªÉ handle streaming

Expected gain: **Perceived -3s** (user th·∫•y response sau ~4s thay v√¨ 7s)


PRIORITY 3 - GI·∫¢M RERANK TOP_K:
--------------------------------
```python
# In query_engine.py
retrieval_top_k = 10  # T·ª´ 20 ‚Üí 10
```
Expected gain: **-200ms**


PRIORITY 4 - AGENT MODEL OPTIMIZATION:
---------------------------------------
- Planning: gpt-5 ‚Üí gpt-5-mini (nhanh h∆°n, r·∫ª h∆°n)
- Final answer: Streaming
Expected gain: **-1s**


TARGET LATENCY sau optimization:
==================================
1. T·∫Øt distillation          : -7s
2. Streaming                 : Perceived -3s
3. Gi·∫£m top_k                : -200ms
4. Agent model optimization  : -1s

TOTAL: 7-8s ‚Üí ~5s perceived (user th·∫•y response sau 2-3s) ‚úÖ
"""

with open('/home/giakiet05/programming/projects/uit-ai-assistant/docs/LATENCY_ANALYSIS.md', 'w') as f:
    f.write(__doc__)

print(__doc__)


=============================================================================
UPDATE - OPTIMIZATION APPLIED (2026-01-10)
=============================================================================

CHANGES MADE:
-------------
1. ‚úÖ Reduced retrieval_top_k: 20 ‚Üí 10
   - Location: query_engine.py (default) + retrieval_tools.py (hardcoded)
   - Impact: Faster reranking (less chunks to process)
   
2. ‚úÖ Increased MCP client timeout: 5min ‚Üí 10min
   - Location: agent/src/tools/mcp_loader.py
   - Impact: Prevent timeout errors with distillation enabled

3. ‚úÖ Context Distillation: KEEP ENABLED with parallel processing
   - Quality improvement: Extract only relevant info
   - Performance: Parallel distillation (~2s instead of ~7s)


EXPECTED NEW LATENCY:
---------------------
Previous WITH distillation (20 chunks):
  - Reranking: ~800ms (20 chunks)
  - Distillation: ~8s (sequential)
  - Total: ~14-15s

NEW WITH distillation (10 chunks):
  - Reranking: ~400ms (10 chunks, -50%)
  - Distillation: ~4s (parallel on 10 chunks, was ~8s on 20)
  - Total: ~10-11s ‚úÖ (-30% improvement)

Further optimization if needed:
  - Distillation can be disabled: USE_CONTEXT_DISTILLATION=false
    ‚Üí Back to ~7-8s total
  - Or increase DISTILLATION_MIN_CHUNKS to trigger less often


TRADE-OFFS:
-----------
‚úÖ PROS:
  - 30% faster (~4s saved)
  - Less API cost (10 chunks vs 20)
  - Better focus (less noise for distillation)

‚ö†Ô∏è CONS:
  - Slightly lower recall (might miss relevant chunks in top 11-20)
  - Mitigation: Reranker is good, top-10 usually enough

MONITORING:
-----------
Watch for:
  - User reports of "kh√¥ng t√¨m th·∫•y th√¥ng tin" tƒÉng
  - If yes: consider increasing back to 15
  - If no: current setting is optimal ‚úÖ
