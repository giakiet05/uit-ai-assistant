
@misc{dang_viranker_2025,
	title = {{ViRanker}: A {BGE}-M3 \& Blockwise Parallel Transformer Cross-Encoder for Vietnamese Reranking},
	url = {http://arxiv.org/abs/2509.09131},
	doi = {10.48550/arXiv.2509.09131},
	shorttitle = {{ViRanker}},
	abstract = {This paper presents {ViRanker}, a cross-encoder reranking model tailored to the Vietnamese language. Built on the {BGE}-M3 encoder and enhanced with the Blockwise Parallel Transformer, {ViRanker} addresses the lack of competitive rerankers for Vietnamese, a low-resource language with complex syntax and diacritics. The model was trained on an 8 {GB} curated corpus and fine-tuned with hybrid hard-negative sampling to strengthen robustness. Evaluated on the {MMARCO}-{VI} benchmark, {ViRanker} achieves strong early-rank accuracy, surpassing multilingual baselines and competing closely with {PhoRanker}. By releasing the model openly on Hugging Face, we aim to support reproducibility and encourage wider adoption in real-world retrieval systems. Beyond Vietnamese, this study illustrates how careful architectural adaptation and data curation can advance reranking in other underrepresented languages.},
	number = {{arXiv}:2509.09131},
	publisher = {{arXiv}},
	author = {Dang, Phuong-Nam and Nguyen, Kieu-Linh and Pham, Thanh-Hieu},
	urldate = {2025-12-23},
	date = {2025-09-11},
	eprinttype = {arxiv},
	eprint = {2509.09131 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/home/giakiet05/Zotero/storage/CUZTQEZK/Dang et al. - 2025 - ViRanker A BGE-M3 & Blockwise Parallel Transformer Cross-Encoder for Vietnamese Reranking.pdf:application/pdf;Snapshot:/home/giakiet05/Zotero/storage/ZS4BP5FZ/2509.html:text/html},
}

@online{noauthor_what_nodate,
	title = {What is the Model Context Protocol ({MCP})?},
	url = {https://modelcontextprotocol.io/docs/getting-started/intro},
	titleaddon = {Model Context Protocol},
	urldate = {2025-12-23},
	langid = {english},
	file = {Snapshot:/home/giakiet05/Zotero/storage/96FNIAAK/intro.html:text/html},
}

@online{noauthor_langgraph_nodate,
	title = {{LangGraph} overview},
	url = {https://docs.langchain.com/oss/python/langgraph/overview},
	abstract = {Gain control with {LangGraph} to design agents that reliably handle complex tasks},
	titleaddon = {Docs by {LangChain}},
	urldate = {2025-12-23},
	langid = {english},
	file = {Snapshot:/home/giakiet05/Zotero/storage/38GAACWH/overview.html:text/html},
}

@misc{singh_agentic_2025,
	title = {Agentic Retrieval-Augmented Generation: A Survey on Agentic {RAG}},
	url = {http://arxiv.org/abs/2501.09136},
	doi = {10.48550/arXiv.2501.09136},
	shorttitle = {Agentic Retrieval-Augmented Generation},
	abstract = {Large Language Models ({LLMs}) have revolutionized artificial intelligence ({AI}) by enabling human like text generation and natural language understanding. However, their reliance on static training data limits their ability to respond to dynamic, real time queries, resulting in outdated or inaccurate outputs. Retrieval Augmented Generation ({RAG}) has emerged as a solution, enhancing {LLMs} by integrating real time data retrieval to provide contextually relevant and up-to-date responses. Despite its promise, traditional {RAG} systems are constrained by static workflows and lack the adaptability required for multistep reasoning and complex task management. Agentic Retrieval-Augmented Generation (Agentic {RAG}) transcends these limitations by embedding autonomous {AI} agents into the {RAG} pipeline. These agents leverage agentic design patterns reflection, planning, tool use, and multiagent collaboration to dynamically manage retrieval strategies, iteratively refine contextual understanding, and adapt workflows to meet complex task requirements. This integration enables Agentic {RAG} systems to deliver unparalleled flexibility, scalability, and context awareness across diverse applications. This survey provides a comprehensive exploration of Agentic {RAG}, beginning with its foundational principles and the evolution of {RAG} paradigms. It presents a detailed taxonomy of Agentic {RAG} architectures, highlights key applications in industries such as healthcare, finance, and education, and examines practical implementation strategies. Additionally, it addresses challenges in scaling these systems, ensuring ethical decision making, and optimizing performance for real-world applications, while providing detailed insights into frameworks and tools for implementing Agentic {RAG}.},
	number = {{arXiv}:2501.09136},
	publisher = {{arXiv}},
	author = {Singh, Aditi and Ehtesham, Abul and Kumar, Saket and Khoei, Tala Talaei},
	urldate = {2025-12-23},
	date = {2025-02-04},
	eprinttype = {arxiv},
	eprint = {2501.09136 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {Preprint PDF:/home/giakiet05/Zotero/storage/3C9MRMRN/Singh et al. - 2025 - Agentic Retrieval-Augmented Generation A Survey on Agentic RAG.pdf:application/pdf},
}

@misc{gao_retrieval-augmented_2024,
	title = {Retrieval-Augmented Generation for Large Language Models: A Survey},
	url = {http://arxiv.org/abs/2312.10997},
	doi = {10.48550/arXiv.2312.10997},
	shorttitle = {Retrieval-Augmented Generation for Large Language Models},
	abstract = {Large Language Models ({LLMs}) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation ({RAG}) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. {RAG} synergistically merges {LLMs}' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of {RAG} paradigms, encompassing the Naive {RAG}, the Advanced {RAG}, and the Modular {RAG}. It meticulously scrutinizes the tripartite foundation of {RAG} frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in {RAG} systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development.},
	number = {{arXiv}:2312.10997},
	publisher = {{arXiv}},
	author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Meng and Wang, Haofen},
	urldate = {2025-12-23},
	date = {2024-03-27},
	eprinttype = {arxiv},
	eprint = {2312.10997 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/home/giakiet05/Zotero/storage/UN456QI5/Gao et al. - 2024 - Retrieval-Augmented Generation for Large Language Models A Survey.pdf:application/pdf;Snapshot:/home/giakiet05/Zotero/storage/29G2S4HY/2312.html:text/html},
}

@misc{han_retrieval-augmented_2025,
	title = {Retrieval-Augmented Generation with Graphs ({GraphRAG})},
	url = {http://arxiv.org/abs/2501.00309},
	doi = {10.48550/arXiv.2501.00309},
	abstract = {Retrieval-augmented generation ({RAG}) is a powerful technique that enhances downstream task execution by retrieving additional information, such as knowledge, skills, and tools from external sources. Graph, by its intrinsic "nodes connected by edges" nature, encodes massive heterogeneous and relational information, making it a golden resource for {RAG} in tremendous real-world applications. As a result, we have recently witnessed increasing attention on equipping {RAG} with Graph, i.e., {GraphRAG}. However, unlike conventional {RAG}, where the retriever, generator, and external data sources can be uniformly designed in the neural-embedding space, the uniqueness of graph-structured data, such as diverse-formatted and domain-specific relational knowledge, poses unique and significant challenges when designing {GraphRAG} for different domains. Given the broad applicability, the associated design challenges, and the recent surge in {GraphRAG}, a systematic and up-to-date survey of its key concepts and techniques is urgently desired. Following this motivation, we present a comprehensive and up-to-date survey on {GraphRAG}. Our survey first proposes a holistic {GraphRAG} framework by defining its key components, including query processor, retriever, organizer, generator, and data source. Furthermore, recognizing that graphs in different domains exhibit distinct relational patterns and require dedicated designs, we review {GraphRAG} techniques uniquely tailored to each domain. Finally, we discuss research challenges and brainstorm directions to inspire cross-disciplinary opportunities. Our survey repository is publicly maintained at https://github.com/Graph-{RAG}/{GraphRAG}/.},
	number = {{arXiv}:2501.00309},
	publisher = {{arXiv}},
	author = {Han, Haoyu and Wang, Yu and Shomer, Harry and Guo, Kai and Ding, Jiayuan and Lei, Yongjia and Halappanavar, Mahantesh and Rossi, Ryan A. and Mukherjee, Subhabrata and Tang, Xianfeng and He, Qi and Hua, Zhigang and Long, Bo and Zhao, Tong and Shah, Neil and Javari, Amin and Xia, Yinglong and Tang, Jiliang},
	urldate = {2025-12-23},
	date = {2025-01-08},
	eprinttype = {arxiv},
	eprint = {2501.00309 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Machine Learning},
	file = {Preprint PDF:/home/giakiet05/Zotero/storage/FJS2CN5V/Han et al. - 2025 - Retrieval-Augmented Generation with Graphs (GraphRAG).pdf:application/pdf;Snapshot:/home/giakiet05/Zotero/storage/PH92MEJW/2501.html:text/html},
}

@online{noauthor_welcome_nodate,
	title = {Welcome to {FastMCP} 2.0!},
	url = {https://gofastmcp.com/getting-started/welcome},
	abstract = {The fast, Pythonic way to build {MCP} servers and clients.},
	titleaddon = {{FastMCP}},
	urldate = {2025-12-23},
	langid = {english},
}

@online{noauthor_chroma_nodate,
	title = {Chroma Docs},
	url = {https://docs.trychroma.com},
	abstract = {Documentation for {ChromaDB}},
	titleaddon = {Chroma Docs},
	urldate = {2025-12-23},
	langid = {english},
	file = {Snapshot:/home/giakiet05/Zotero/storage/W3IND7IQ/docs.trychroma.com.html:text/html},
}

@online{noauthor_welcome_nodate-1,
	title = {Welcome to {LlamaIndex} ðŸ¦™ ! {\textbar} {LlamaIndex} Python Documentation},
	url = {https://developers.llamaindex.ai/python/framework/},
	urldate = {2025-12-23},
	file = {Welcome to LlamaIndex ðŸ¦™ ! | LlamaIndex Python Documentation:/home/giakiet05/Zotero/storage/5NLCTSYC/framework.html:text/html},
}

@online{noauthor_react_nodate,
	title = {{ReAct}: Synergizing Reasoning and Acting in Language Models},
	url = {https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/},
	shorttitle = {{ReAct}},
	abstract = {Posted by Shunyu Yao, Student Researcher, and Yuan Cao, Research Scientist, Google Research, Brain Team {\textless}!----{\textgreater} Recent advances have expanded the a...},
	urldate = {2025-12-23},
	langid = {english},
	file = {Snapshot:/home/giakiet05/Zotero/storage/WVZDN7LT/react-synergizing-reasoning-and-acting-in-language-models.html:text/html},
}

@inproceedings{sawarkar_blended_2024,
	title = {Blended {RAG}: Improving {RAG} (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers},
	url = {http://arxiv.org/abs/2404.07220},
	doi = {10.1109/MIPR62202.2024.00031},
	shorttitle = {Blended {RAG}},
	abstract = {Retrieval-Augmented Generation ({RAG}) is a prevalent approach to infuse a private knowledge base of documents with Large Language Models ({LLM}) to build Generative Q{\textbackslash}\&A (Question-Answering) systems. However, {RAG} accuracy becomes increasingly challenging as the corpus of documents scales up, with Retrievers playing an outsized role in the overall {RAG} accuracy by extracting the most relevant document from the corpus to provide context to the {LLM}. In this paper, we propose the 'Blended {RAG}' method of leveraging semantic search techniques, such as Dense Vector indexes and Sparse Encoder indexes, blended with hybrid query strategies. Our study achieves better retrieval results and sets new benchmarks for {IR} (Information Retrieval) datasets like {NQ} and {TREC}-{COVID} datasets. We further extend such a 'Blended Retriever' to the {RAG} system to demonstrate far superior results on Generative Q{\textbackslash}\&A datasets like {SQUAD}, even surpassing fine-tuning performance.},
	pages = {155--161},
	booktitle = {2024 {IEEE} 7th International Conference on Multimedia Information Processing and Retrieval ({MIPR})},
	author = {Sawarkar, Kunal and Mangal, Abhilasha and Solanki, Shivam Raj},
	urldate = {2025-12-23},
	date = {2024-08-07},
	eprinttype = {arxiv},
	eprint = {2404.07220 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {Full Text PDF:/home/giakiet05/Zotero/storage/9QMSTDC7/Sawarkar et al. - 2024 - Blended RAG Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid.pdf:application/pdf;Snapshot:/home/giakiet05/Zotero/storage/HHRTKK85/2404.html:text/html},
}
