# Node Splitters Documentation

ThÆ° má»¥c nÃ y chá»©a cÃ¡c node splitters Ä‘á»ƒ chunk documents thÃ nh nodes cho indexing.

**âš ï¸ IMPORTANT:** Táº¥t cáº£ splitters Ä‘Ã£ Ä‘Æ°á»£c refactored vÃ  moved vÃ o `src/indexing/splitters/`.

## ğŸ“ New Structure

```
src/indexing/
â”œâ”€â”€ splitters/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_node_splitter.py          # Abstract base class
â”‚   â”œâ”€â”€ simple_node_splitter.py        # Simple header-based splitting
â”‚   â”œâ”€â”€ smart_node_splitter.py         # Enhanced splitting (RECOMMENDED)
â”‚   â”œâ”€â”€ hierarchical_node_splitter.py  # Legacy with hierarchy tracking
â”‚   â””â”€â”€ hierarchical_node_splitter_v1.py  # Deprecated (has bugs)
â”œâ”€â”€ builder.py                          # DocumentIndexer (uses SmartNodeSplitter)
â””â”€â”€ PARSERS_README.md                   # This file
```

## ğŸ“¦ Import Examples

```python
# New imports (correct)
from src.knowledge_builder.indexing.splitters import SmartNodeSplitter, SimpleNodeSplitter
from src.knowledge_builder.indexing.indexer import DocumentIndexer

# Old imports (DEPRECATED - will not work)
from src.knowledge_builder.indexing import SmartHeaderParser  # âŒ
from src.knowledge_builder.indexing import HierarchicalMarkdownParserV2  # âŒ
```

---

## ğŸ“‹ Available Splitters

### 1. **BaseNodeSplitter** (Abstract Base Class)

**File:** `splitters/base_node_splitter.py`

Abstract base class providing shared functionality for all splitters:
- Token counting (tiktoken)
- Context prepending (document metadata + section info)
- Sub-chunking logic for large chunks
- Stats tracking

**Usage:** Extend this class when creating new splitters.

```python
from src.knowledge_builder.indexing.splitters import BaseNodeSplitter


class MyCustomSplitter(BaseNodeSplitter):
    def _parse_by_headers(self, text: str) -> List[Dict]:
        # Implement your parsing logic
        pass
```

---

### 2. **SimpleNodeSplitter** â­ (Good baseline)

**File:** `splitters/simple_node_splitter.py`

- âœ… Parse by headers (preserve section boundaries)
- âœ… Track ONLY current header (no hierarchy)
- âœ… Robust against LlamaParse hierarchy errors
- âœ… Simpler, more reliable

**When to use:**
- Good baseline cho production
- Documents parsed tá»« PDF (OCR, LlamaParse)
- Curriculum documents (khÃ´ng cáº§n special handling)

**Trade-off:**
- âŒ KhÃ´ng biáº¿t "Äiá»u X thuá»™c ChÆ°Æ¡ng Y"
- âŒ Title cÃ³ thá»ƒ bá»‹ split thÃ nh nhiá»u chunks
- NhÆ°ng: Váº«n work tá»‘t cho retrieval

**Example context:**
```
TÃ i liá»‡u: Quy Cháº¿ ÄÃ o Táº¡o
TiÃªu Ä‘á»: Quy cháº¿ Ä‘Ã o táº¡o theo há»c cháº¿ tÃ­n chá»‰
Pháº§n: Äiá»u 10. Cháº¿ Ä‘á»™ há»c táº­p
NgÃ y hiá»‡u lá»±c: 2022-09-28
---
## Äiá»u 10. Cháº¿ Ä‘á»™ há»c táº­p
...
```

**Usage:**

```python
from src.knowledge_builder.indexing.splitters import SimpleNodeSplitter

splitter = SimpleNodeSplitter(
    max_tokens=7000,
    sub_chunk_size=1024,
    sub_chunk_overlap=200
)
nodes = splitter.get_nodes_from_documents(documents)
```

---

### 3. **SmartNodeSplitter** â­â­â­ (RECOMMENDED)

**File:** `splitters/smart_node_splitter.py`

- âœ… All benefits of SimpleNodeSplitter
- âœ… **Title chunk merging** (regulation: first 3-4 short chunks â†’ 1)
- âœ… **Pattern detection** (Äiá»u X, CHÆ¯Æ NG X)
- âœ… **Malformed markdown cleanup** (empty headers)
- âœ… Optimized cho Vietnamese regulation documents

**When to use:**
- **DEFAULT choice cho regulation documents** ğŸ“‹
- PDF-based documents vá»›i title split issues
- Documents vá»›i Äiá»u/CHÆ¯Æ NG patterns

**Improvements over SimpleNodeSplitter:**

1. **Title merging**:
   ```
   Before: Chunk 1: "QUY CHáº¾"
           Chunk 2: "ÄÃ€O Táº O..."
           Chunk 3: "Cá»¦A TRÆ¯á»œNG..."

   After:  Chunk 1: "QUY CHáº¾ ÄÃ€O Táº O..." (merged)
           Chunk 2: "Má»¤C Lá»¤C"
           Chunk 3: "Äiá»u 1..."
   ```

2. **Pattern detection**:
   - Detects **Äiá»u X.** (even without markdown headers)
   - Detects **CHÆ¯Æ NG X** (Roman/Arabic numerals)
   - Handles malformed markdown from LlamaParse

3. **Markdown cleanup**:
   - Removes empty headers (`##\n`)
   - Fixes standalone separators

**Example context:**
```
TÃ i liá»‡u: 790 Qd Dhcntt 28 9 22 Quy Che Dao Tao
TiÃªu Ä‘á»: QUY CHáº¾ ÄÃ€O Táº O THEO Há»ŒC CHáº¾ TÃN CHá»ˆ...
Pháº§n: Äiá»u 10. Cháº¿ Ä‘á»™ há»c táº­p
Loáº¡i: VÄƒn báº£n gá»‘c
---
## Äiá»u 10. Cháº¿ Ä‘á»™ há»c táº­p
...
```

**Usage:**

```python
from src.knowledge_builder.indexing.splitters import SmartNodeSplitter

splitter = SmartNodeSplitter(
    max_tokens=7000,
    sub_chunk_size=1024,
    sub_chunk_overlap=200,
    enable_title_merging=True,  # Merge title chunks
    enable_pattern_detection=True  # Detect Äiá»u/CHÆ¯Æ NG patterns
)
nodes = splitter.get_nodes_from_documents(documents)

# Get stats
stats = splitter.get_stats()
print(f"Title chunks merged: {stats['title_chunks_merged']}")
print(f"Patterns detected: {stats['patterns_detected']}")
```

---

### 4. **HierarchicalNodeSplitter** (Legacy)

**File:** `splitters/hierarchical_node_splitter.py`

- âœ… Parse by headers, track hierarchy (fixed duplicate issue from V1)
- âœ… Prepend full context: `Cáº¥u trÃºc: Parent > Child > Current`
- âœ… Token-aware sub-chunking
- âš ï¸  **Vulnerable to hierarchy errors from LlamaParse**

**When to use:**
- Document cÃ³ markdown structure tá»‘t (headers chÃ­nh xÃ¡c)
- Muá»‘n giá»¯ full hierarchy info
- Tin tÆ°á»Ÿng LlamaParse output

**Known issue:**
- LlamaParse cÃ³ thá»ƒ táº¡o sai header levels (e.g., Äiá»u 33 lÃ  ##, Äiá»u 34 lÃ  ###)
- Dáº«n Ä‘áº¿n hierarchy path sai â†’ context misleading

**Example context:**
```
TÃ i liá»‡u: Quy Cháº¿ ÄÃ o Táº¡o
TiÃªu Ä‘á»: Quy cháº¿ Ä‘Ã o táº¡o theo há»c cháº¿ tÃ­n chá»‰
Cáº¥u trÃºc: CHÆ¯Æ NG 2 > Äiá»u 10 > Khoáº£n 1
NgÃ y hiá»‡u lá»±c: 2022-09-28
---
## Äiá»u 10. Cháº¿ Ä‘á»™ há»c táº­p
...
```

**Usage:**

```python
from src.knowledge_builder.indexing.splitters import HierarchicalNodeSplitter

splitter = HierarchicalNodeSplitter(
    max_tokens=7000,
    sub_chunk_size=1024,
    sub_chunk_overlap=200
)
nodes = splitter.get_nodes_from_documents(documents)
```

---

### 5. **HierarchicalNodeSplitterV1** âŒ (Deprecated)

**File:** `splitters/hierarchical_node_splitter_v1.py`

- âŒ **DEPRECATED** - Has duplicate header bug
- âŒ Do not use

**Status:** Kept for backwards compatibility only. Use `SmartNodeSplitter` or `HierarchicalNodeSplitter` instead.

---

## ğŸ† Recommendation Table

| Document Type | Recommended Splitter | Reason |
|---------------|---------------------|--------|
| **Regulation** | `SmartNodeSplitter` | Title merging + pattern detection |
| **Curriculum** | `SimpleNodeSplitter` | No special handling needed |
| **Clean markdown** | `HierarchicalNodeSplitter` | If you trust header levels |
| **PDF documents** | `SmartNodeSplitter` | Robust against parsing errors |

---

## ğŸ”§ Configuration

All splitters use centralized settings from `src/config/settings.py`:

```python
# settings.py (example)
class RetrievalConfig:
    MAX_TOKENS = 7000           # Max tokens before sub-chunking
    CHUNK_SIZE = 1024           # Sub-chunk target size
    CHUNK_OVERLAP = 200         # Sub-chunk overlap
    EMBED_MODEL = "text-embedding-3-small"
```

Override in splitter initialization:
```python
splitter = SmartNodeSplitter(
    max_tokens=5000,            # Override
    sub_chunk_size=512,         # Override
    sub_chunk_overlap=100       # Override
)
```

---

## ğŸ“Š Stats Tracking

All splitters track statistics:

```python
splitter = SmartNodeSplitter()
nodes = splitter.get_nodes_from_documents(documents)

stats = splitter.get_stats()
print(stats)
# {
#     'total_chunks': 142,
#     'large_chunks_split': 3,
#     'final_nodes': 148,
#     'title_chunks_merged': 3,    # SmartNodeSplitter only
#     'patterns_detected': 12      # SmartNodeSplitter only
# }
```

---

## ğŸ§ª Testing

Test files updated with new imports:
- `test/test_simple_header_parser.py` â†’ uses `SimpleNodeSplitter`
- `test/test_smart_header_parser.py` â†’ uses `SmartNodeSplitter`
- `test/test_smart_parser_simple.py` â†’ standalone test

Run tests:
```bash
python test/test_smart_header_parser.py
```

---

## ğŸš€ Migration Guide

### Old Code (before refactor):

```python
from src.knowledge_builder.indexing import SmartHeaderParser
from src.knowledge_builder.indexing.indexer import RagBuilder

parser = SmartHeaderParser()
builder = RagBuilder(domain="daa.uit.edu.vn")
builder.build_all_collections()
```

### New Code (after refactor):

```python
from src.knowledge_builder.indexing.splitters import SmartNodeSplitter
from src.knowledge_builder.indexing.indexer import DocumentIndexer

# Splitter is automatically used by DocumentIndexer
indexer = DocumentIndexer()  # No domain needed
indexer.build_all_collections(categories=["regulation", "curriculum"])
```

**Key changes:**
1. âœ… `SmartHeaderParser` â†’ `SmartNodeSplitter`
2. âœ… `RagBuilder` â†’ `DocumentIndexer`
3. âœ… No more `domain` parameter (flat structure: `processed/{category}/`)
4. âœ… Import from `src.indexing.splitters`

---

## ğŸ“ Architecture

```
BaseNodeSplitter (abstract)
    â”œâ”€â”€ count_tokens()
    â”œâ”€â”€ _prepend_context()
    â”œâ”€â”€ _process_chunks_with_token_check()
    â”œâ”€â”€ get_nodes_from_documents()
    â””â”€â”€ _parse_by_headers() [ABSTRACT]
         â”‚
         â”œâ”€â”€ SimpleNodeSplitter
         â”‚   â””â”€â”€ Simple header parsing
         â”‚
         â”œâ”€â”€ SmartNodeSplitter
         â”‚   â”œâ”€â”€ _preprocess_markdown()
         â”‚   â”œâ”€â”€ _merge_title_chunks()
         â”‚   â”œâ”€â”€ _is_section_marker()
         â”‚   â””â”€â”€ _post_process_chunks()
         â”‚
         â””â”€â”€ HierarchicalNodeSplitter
             â””â”€â”€ Hierarchy tracking logic
```

**Benefits of OOP design:**
- âœ… Code reuse (no duplication)
- âœ… Easy to extend (add new splitters)
- âœ… Consistent interface
- âœ… Centralized token counting & context logic

---

## â“ FAQ

**Q: Which splitter should I use?**
A: Use `SmartNodeSplitter` for regulations, `SimpleNodeSplitter` for curriculum.

**Q: Why did you rename parsers to splitters?**
A: Avoid confusion with PDF parsers (LlamaParse). "Splitter" follows LlamaIndex convention.

**Q: Can I use the old imports?**
A: No, old files have been deleted. Update your imports to `src.indexing.splitters`.

**Q: How do I create a custom splitter?**
A: Extend `BaseNodeSplitter` and implement `_parse_by_headers()`.

**Q: Where is the CLI?**
A: CLI code removed from `builder.py` (handled by `cli.py` now).

---

## ğŸ“š References

- **LlamaIndex Docs:** https://docs.llamaindex.ai/
- **Tiktoken:** https://github.com/openai/tiktoken
- **ChromaDB:** https://www.trychroma.com/
